"""
        You are an assistant designed to break down a complex data science or geospatial analysis task 
        into smaller, focused sub-queries. Each sub-query must target a specific technical domain 
        so that relevant documentation, examples, or code can be retrieved using a vector database.

        Given the user query, return 3 clearly separated sub-queries:

        1. HDF5 Dataset Access:
        Focus only on `h5py` such as accessing file with extensions H5, h5, HE5, he5, HDF5, or hdf5, 
        accessing datasets or attributes, dataset paths (like `/Grid/cloudWater`), and metadata.

        2. NumPy-based Data Preprocessing:
        Focus only on how to handle `_FillValue`, apply masks using NumPy (`np.where`, `np.ma.masked_where`), and compute or filter data using `min`, `max`, or 
        other preprocessing logic.

        3. Map Plotting and Visualization:
        Focus only on how to use `matplotlib`, `mpl_toolkits.basemap`, or `cartopy` to visualize geospatial data, configure projections, draw coastlines, 
        meridians, parallels, and apply colorbars or titles.

        
        User Query:
            1. Import Libraries: Include necessary modules for OS operations, plotting, numerical computations, map projections, and HDF5 handling.

2. Define Constants: Set `FILE_NAME` to "ATL06_20190223232535_08780212_006_02.h5".

3. Read HDF5 Data: Open the file in read mode and extract datasets for 
    `/gt1l/land_ice_segments/latitude` latitude data, 
    `/gt1l/land_ice_segments/longitude` longitude data, 
and `/gt1l/land_ice_segments/h_li` main data  
Retrieve attributes using decode() and handle _FillValue.

4. Preprocess Data: Replace _FillValue in h_li with NaNs and mask invalid data using numpy functions.

5. Create Map: Using an equidistant cylindrical projection map 
with low resolution and latitude and longitude values from -90 to 90 and -180 to 180 respectively. 
It also adds coastlines with linewidth of 0.5, 
parallels with parameters of nummpy arrange with values -90, 120, 30, 
and meridians with parameters numpy arrange -180, 180, 45

6. Plot Data: 
The program should set scatter function with parameters of longitude, latitude, c=data, s=0.1, cmap=plt.cm.jet, edgecolors=None, and linewidth=0
Generate a scatter plot of the data with given parameters including colormap and marker size.

7. Add Colorbar and Title: Include a colorbar labeled with dataset units and set the title using the file's basename and long_name.

        ---
        Note: return only the the response of sub-queries only based on the below format, not explanation, not python code, and node additional text needed
        Return format:

        HDF5 Dataset Access Sub-query:
        <generated sub-query>

        NumPy Data Preprocessing Sub-query:
        <generated sub-query>

        Plotting and Visualization Sub-query:
        <generated sub-query>
        """

HDF5 Dataset Access Sub-query:
How to use `h5py` to open an HDF5 file (e.g., `"ATL06_20190223232535_08780212_006_02.h5"`), read the datasets at paths `"/gt1l/land_ice_segments/latitude"`, `"/gt1l/land_ice_segments/longitude"`, and `"/gt1l/land_ice_segments/h_li"`, retrieve and decode dataset attributes (e.g., `long_name`, `units`), and identify the `_FillValue` attribute for the `h_li` dataset.

NumPy Data Preprocessing Sub-query:
What is the correct NumPy approach to replace the `_FillValue` in the `h_li` array with `np.nan`, apply a mask to exclude invalid data using functions such as `np.where`, `np.ma.masked_where`, and compute basic statistics (min, max) on the cleaned data.

Plotting and Visualization Sub-query:
How to create an equidistant cylindrical map (low resolution) using `matplotlib`/`cartopy`, plot latitude/longitude scatter points with color mapping from the `h_li` data (using `cmap=plt.cm.jet`, point size 0.1, no edge colors), add coastlines (linewidth 0.5), parallels at -90, -60, -30, 0, 30, 60, 90 and meridians at -180, -135, -90, -45, 0, 45, 90, 135, 180, and finally add a colorbar labeled with the dataset units and set the plot title using the file basename and the dataset’s `long_name`.